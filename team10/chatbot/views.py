from django.shortcuts import render
import threading
import gradio as gr
from django.http import HttpResponse
# -----------
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.document_loaders import CSVLoader
import dotenv
dotenv.load_dotenv()
import time

persist_directory = './'
embedding = OpenAIEmbeddings()

# load from disk
vectorstore = Chroma(
    persist_directory=persist_directory,
    embedding_function=embedding)

retriever = vectorstore.as_retriever()

from langchain.agents.agent_toolkits import create_retriever_tool

tool = create_retriever_tool(
    retriever,
    "BarunJaseDowoomi_customer_service_guide",
    "Searches and returns information regarding the customer service guide.",
)
tools = [tool]

from langchain.chat_models import ChatOpenAI
llm = ChatOpenAI(temperature=0, model='gpt-3.5-turbo-1106')

# This is needed for both the memory and the prompt
memory_key = "history"

from langchain.agents.openai_functions_agent.agent_token_buffer_memory import (
    AgentTokenBufferMemory,
)

memory = AgentTokenBufferMemory(memory_key=memory_key, llm=llm)

from langchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent
from langchain.schema.messages import SystemMessage
from langchain.prompts import MessagesPlaceholder

system_message = SystemMessage(
    content=(
        "You are a customer service agent for 'ë°”ë¥¸ìì„¸ ë„ìš°ë¯¸'. "
        "Do your best to answer the questions within the scope of our service. "
        "Please do not provide answers that deviate from the subject matter. "
        "Feel free to use any tools available to look up "
        "relevant information, only if necessary"
        "If you don't know the answer, just say you don't know. Don't try to make up an answer."
        "Make sure to answer in Korean"
    )
)

prompt = OpenAIFunctionsAgent.create_prompt(
    system_message=system_message,
    extra_prompt_messages=[MessagesPlaceholder(variable_name=memory_key)],
)

agent = OpenAIFunctionsAgent(llm=llm, tools=tools, prompt=prompt)

from langchain.agents import AgentExecutor

agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    memory=memory,
    verbose=True,
    return_intermediate_steps=True,
)

# result = agent_executor({"input": "ì‚¬ìš©ìš”ê¸ˆ ì¡°íšŒëŠ” ì–´ë–»ê²Œ í•˜ì£ "})
# result["output"]

# ---------------- ~ langchain model ë§Œë“¤ê¸° -------------
# LangChain ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ í•„ìš”í•œ ì»´í¬ë„ŒíŠ¸ ê°€ì ¸ì˜¤ê¸°
from langchain.chat_models import ChatOpenAI
from langchain.schema import AIMessage, HumanMessage, SystemMessage

# GPT-3.5 ëª¨ë¸ê³¼ íˆìŠ¤í† ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ ì •ì˜
def response(message, history, additional_input_info):
    history_langchain_format = []
    for human, ai in history:
        history_langchain_format.append(HumanMessage(content=human))
        history_langchain_format.append(AIMessage(content=ai))
    # ìƒˆë¡œìš´ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    history_langchain_format.append(HumanMessage(content=message))
    
    # AgentExecutorë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±
    result = agent_executor({"input": message, "history": history_langchain_format})
    
    # LangChainì˜ ì¶œë ¥ì—ì„œ AIì˜ ë§ˆì§€ë§‰ ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
    ai_response = result['output']
    return ai_response

# Gradio ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤ êµ¬ì„± ë° ì‹¤í–‰
# gr.ChatInterface(
#     fn=response,
#     textbox=gr.Textbox(placeholder="ì—¬ê¸°ì— ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...", container=False, scale=7),
#     chatbot=gr.Chatbot(height=1000),  # ì±„íŒ…ì°½ì˜ ë†’ì´ ì¡°ì ˆ
#     title="ë°”ë¥¸ìì„¸ ë„ìš°ë¯¸ ì±—ë´‡",
#     description="ê³ ê° ì„œë¹„ìŠ¤ ê´€ë ¨ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤. ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.",
#     theme="monochrome",  # ì¸í„°í˜ì´ìŠ¤ í…Œë§ˆ ì„¤ì •
#     examples=[["ì•ˆë…•í•˜ì„¸ìš”"], ["ë°°ì†¡ ìƒíƒœë¥¼ ì•Œê³  ì‹¶ì–´ìš”"]],
#     retry_btn="ë‹¤ì‹œ ì…ë ¥ â†©",
#     undo_btn="ì´ì „ ë©”ì‹œì§€ ì‚­ì œ âŒ",
#     clear_btn="ì±„íŒ… ê¸°ë¡ ì‚­ì œ ğŸ’«",
#     additional_inputs=[
#         gr.Textbox("", label="ì¶”ê°€ ì…ë ¥ ì •ë³´", placeholder="ì—¬ê¸°ì— ì¶”ê°€ ì •ë³´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
#     ]
# ).launch(share=True)

def launch_gradio():
    gr.Interface(
        fn=response,
        textbox=gr.Textbox(placeholder="ì—¬ê¸°ì— ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...", container=False, scale=7),
        chatbot=gr.Chatbot(height=500),  # ì±„íŒ…ì°½ì˜ ë†’ì´ ì¡°ì ˆ
        description="ê³ ê° ì„œë¹„ìŠ¤ ê´€ë ¨ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤. ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.",
        theme="monochrome",  # ì¸í„°í˜ì´ìŠ¤ í…Œë§ˆ ì„¤ì •
        examples=[["ì•ˆë…•í•˜ì„¸ìš”"], ["ë°°ì†¡ ìƒíƒœë¥¼ ì•Œê³  ì‹¶ì–´ìš”"]],
        retry_btn="ë‹¤ì‹œ ì…ë ¥ â†©",
        undo_btn="ì´ì „ ë©”ì‹œì§€ ì‚­ì œ âŒ",
        clear_btn="ì±„íŒ… ê¸°ë¡ ì‚­ì œ ğŸ’«",
        additional_inputs=[
            gr.Textbox("", label="ì¶”ê°€ ì…ë ¥ ì •ë³´", placeholder="ì—¬ê¸°ì— ì¶”ê°€ ì •ë³´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        ]
    ).launch(share=True, server_name="127.0.0.1", server_port=7860)
# gradio ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰
threading.Thread(target=launch_gradio, daemon=True).start()

def chatbot_view(request):
    return render(request, 'chatbot/chatbot.html')

